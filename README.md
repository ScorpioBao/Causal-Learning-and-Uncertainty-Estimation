# Cusal-Learning-and-uncertainty-estimation
è¯¥ç«™ç‚¹ç”¨äºæ•´ç†æœ¬äººç ”ç©¶ç”ŸæœŸé—´ç›¸å…³ç ”ç©¶æ–¹å‘çš„å­¦ä¹ èµ„æºï¼ŒåŒ…æ‹¬è®ºæ–‡ã€ä»£ç ã€æ•°æ®é›†å’Œåšå®¢ç­‰å­¦ä¹ èµ„æºç­‰ã€‚
# ç›®å½•
#### ä¸€ã€è®ºæ–‡
- [å› æœæ¨ç†](https://github.com/ScorpioBao/Causal-Learning-and-Uncertainty-Estimation/tree/master/Causal%20Learning)
	- [å› æœæ•ˆåº”è¯„ä¼°ï¼ˆCausal Effect Estimationï¼‰](https://github.com/ScorpioBao/Causal-Learning-and-Uncertainty-Estimation/tree/master/Causal%20Learning/Causal%20Effect%20Estmation))
	- [å› æœå‘ç°ï¼ˆCausal Discoveryï¼‰](https://github.com/ScorpioBao/Causal-Learning-and-Uncertainty-Estimation/tree/master/Causal%20Learning/Causal%20Discovery)
- [å› æœè¡¨å¾å­¦ä¹ ](#2å› æœè¡¨å¾å­¦ä¹ )
	- [åˆ†å¸ƒå¤–æ³›åŒ–ï¼ˆOut-of-Distribution Generalizationï¼‰](#1åˆ†å¸ƒå¤–æ³›åŒ–)
	- [ç¨³å®šå­¦ä¹ ï¼ˆStable Learningï¼‰](#2ç¨³å®šå­¦ä¹ )
	- [æ¶ˆé™¤åå·®ï¼ˆDebiasï¼‰](#3æ¶ˆé™¤åå·®)
-  [ä¸ç¡®å®šæ€§ä¼°è®¡](#3ä¸ç¡®å®šæ€§ä¼°è®¡)
	- [ç»¼è¿°](#1ç»¼è¿°)
	- [è´å¶æ–¯æ–¹æ³•ï¼ˆBayesianï¼‰](#2è´å¶æ–¯æ–¹æ³•)
	- [é›†æˆæ–¹æ³•ï¼ˆEnsembleï¼‰](#3é›†æˆæ–¹æ³•)
	- [è¯æ®æ·±åº¦å­¦ä¹ ï¼ˆEvidential Deep Learning)](#4è¯æ®æ·±åº¦å­¦ä¹ )
- [ ä¸ç¡®å®šæ€§ä¼°è®¡åœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨](#4ä¸ç¡®å®šæ€§ä¼°è®¡åœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨)
	- [åˆ†å‰²](#1åˆ†å‰²)
	- [ç›®æ ‡æ£€æµ‹](#2ç›®æ ‡æ£€æµ‹)
	- [å¼€é›†è¯†åˆ«](#3å¼€é›†è¯†åˆ«)
	- [åˆ†å¸ƒå¤–æ³›åŒ–](#4åˆ†å¸ƒå¤–æ³›åŒ–)
	- [å¤šè§†å›¾å­¦ä¹ ](#5å¤šè§†å›¾å­¦ä¹ )
- [æ·±åº¦å­¦ä¹ æ¨¡å‹æ ¡å‡†çš„ç›¸å…³å·¥ä½œ]()
- [ä»£ç å’Œæ•°æ®é›†](#äºŒä»£ç å’Œæ•°æ®é›†)
- [åšå®¢](#ä¸‰åšå®¢)
	- å› æœæ¨ç†
	- ä¸ç¡®å®šæ€§ä¼°è®¡
	- æ¨¡å‹æ ¡å‡†

# ä¸€ã€è®ºæ–‡
### 1ã€ å› æœæ¨ç†(ç›¸å…³è®ºæ–‡å¯ä»¥é€šè¿‡ç›®å½•ä¸­çš„é“¾æ¥è®¿é—®)
### 2ã€ å› æœè¡¨å¾å­¦ä¹ 
#### ï¼ˆ1ï¼‰ç»¼è¿°
- SchÃ¶lkopf, B., Locatello, F., Bauer, S., Ke, N. R., Kalchbrenner, N., Goyal, A., & Bengio, Y. (2021). Toward causal representation learning.Â _Proceedings of the IEEE_,Â _109_(5), 612-634.ï¼ˆå› æœè¡¨å¾å­¦ä¹ ç»¼è¿°ï¼‰
- Lu, C., Wu, Y., HernÃ¡ndez-Lobato, J. M., & SchÃ¶lkopf, B. (2021). Invariant causal representation learning for out-of-distribution generalization. InÂ _International Conference on Learning Representations_.ï¼ˆä¸å˜å› æœè¡¨å¾å­¦ä¹ ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ2ï¼‰åˆ†å¸ƒå¤–æ³›åŒ–
*ç›¸å…³è®ºæ–‡å¯ä»¥åœ¨[åˆ†å¸ƒå¤–æ³›åŒ–](https://github.com/ScorpioBao/Causal-Learning-and-Uncertainty-Estimation/tree/master/Causal%20Representation%20Learning/Out-of-Distribution%20Generalization)æ–‡ä»¶å¤¹ä¸‹æŸ¥çœ‹*
- Xu, R., Zhang, X., Shen, Z., Zhang, T., & Cui, P. (2022, June). A Theoretical Analysis on Independence-driven Importance Weighting for Covariate-shift Generalization. InÂ _International Conference on Machine Learning_Â (pp. 24803-24829). PMLR.ï¼ˆåå˜é‡åç§»ï¼‰
- Liu, C., Sun, X., Wang, J., Tang, H., Li, T., Qin, T., ... & Liu, T. Y. (2021). Learning causal semantic representation for out-of-distribution prediction.Â _Advances in Neural Information Processing Systems_,Â _34_, 6155-6170.ï¼ˆå› æœè¯­ä¹‰è¡¨ç¤ºå­¦ä¹ ï¼‰
- Zhang, X., Xu, Z., Xu, R., Liu, J., Cui, P., Wan, W., ... & Li, C. (2022). Towards domain generalization in object detection.Â _arXiv preprint arXiv:2203.14387_.ï¼ˆç›®æ ‡æ£€æµ‹ä¸­çš„åŸŸæ³›åŒ–ï¼‰
- Shen, Z., Liu, J., He, Y., Zhang, X., Xu, R., Yu, H., & Cui, P. (2021). Towards out-of-distribution generalization: A survey.Â _arXiv preprint arXiv:2108.13624_.ï¼ˆç»¼è¿°ï¼‰
- Li, X., Dai, Y., Ge, Y., Liu, J., Shan, Y., & Duan, L. Y. (2022). Uncertainty modeling for out-of-distribution generalization.Â _arXiv preprint arXiv:2202.03958_.ï¼ˆOODGä¸ç¡®å®šæ€§å»ºæ¨¡ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ3ï¼‰ç¨³å®šå­¦ä¹ 
*ç›¸å…³è®ºæ–‡å¯ä»¥åœ¨[ç¨³å®šå­¦ä¹ ](https://github.com/ScorpioBao/Causal-Learning-and-Uncertainty-Estimation/tree/master/Causal%20Representation%20Learning/Stable%20Learning)æ–‡ä»¶å¤¹ä¸‹æŸ¥çœ‹*
- Zhang, X., Cui, P., Xu, R., Zhou, L., He, Y., & Shen, Z. (2021). Deep stable learning for out-of-distribution generalization. InÂ _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_Â (pp. 5372-5382).ï¼ˆStableNetï¼‰
- Liu, J., Hu, Z., Cui, P., Li, B., & Shen, Z. (2021, July). Heterogeneous risk minimization. InÂ _International Conference on Machine Learning_Â (pp. 6804-6814). PMLR.ï¼ˆå¼‚è´¨é£é™©æœ€å°åŒ–ï¼‰
- Cui, P., & Athey, S. (2022). Stable learning establishes some common ground between causal inference and machine learning.Â _Nature Machine Intelligence_,Â _4_(2), 110-115.ï¼ˆç¨³å®šå­¦ä¹ ä¸å› æœæ¨æ–­å’Œæœºå™¨å­¦ä¹ ä¹‹é—´çš„å…±åŒç‚¹ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ4ï¼‰æ¶ˆé™¤åå·®
- Wang, T., Zhou, C., Sun, Q., & Zhang, H. (2021). Causal attention for unbiased visual recognition. InÂ _Proceedings of the IEEE/CVF International Conference on Computer Vision_Â (pp. 3091-3100).ï¼ˆå› æœæ³¨æ„åŠ›ï¼‰
- Niu, Y., Tang, K., Zhang, H., Lu, Z., Hua, X. S., & Wen, J. R. (2021). Counterfactual vqa: A cause-effect look at language bias. InÂ _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_Â (pp. 12700-12710).ï¼ˆåäº‹å®VQAï¼‰
- Yang, X., Zhang, H., & Cai, J. (2021). Deconfounded image captioning: A causal retrospect.Â _IEEE Transactions on Pattern Analysis and Machine Intelligence_.ï¼ˆå»é™¤æ··æ·†åå·®ï¼‰
- Nam, J., Cha, H., Ahn, S., Lee, J., & Shin, J. (2020). Learning from failure: De-biasing classifier from biased classifier.Â _Advances in Neural Information Processing Systems_,Â _33_, 20673-20684.ï¼ˆä»æœ‰ååˆ†ç±»å™¨å­¦ä¹ å»ååˆ†ç±»å™¨ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
### 3ã€ä¸ç¡®å®šæ€§ä¼°è®¡
#### ï¼ˆ1ï¼‰ç»¼è¿°
- Gawlikowski, J., Tassi, C. R. N., Ali, M., Lee, J., Humt, M., Feng, J., ... & Zhu, X. X. (2021). A survey of uncertainty in deep neural networks.Â _arXiv preprint arXiv:2107.03342_.
- Abdar, M., Pourpanah, F., Hussain, S., Rezazadegan, D., Liu, L., Ghavamzadeh, M., ... & Nahavandi, S. (2021). A review of uncertainty quantification in deep learning: Techniques, applications and challenges.Â _Information Fusion_,Â _76_, 243-297.
- Uncertainty in Deep Learningï¼ˆGalåšå£«è®ºæ–‡ï¼‰
- He, W., & Jiang, Z. (2023). A Survey on Uncertainty Quantification Methods for Deep Neural Networks: An Uncertainty Source Perspective.Â _arXiv preprint arXiv:2302.13425_.
- HÃ¼llermeier, E., & Waegeman, W. (2021). Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods.Â _Machine Learning_,Â _110_, 457-506.ï¼ˆæ•°æ®å’Œæ¨¡å‹ä¸ç¡®å®šæ€§ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ2ï¼‰è´å¶æ–¯æ–¹æ³•ï¼š
- Gal, Y., & Ghahramani, Z. (2016, June). Dropout as a bayesian approximation: Representing model uncertainty in deep learning. InÂ _international conference on machine learning_Â (pp. 1050-1059). PMLR.ï¼ˆå°†Dropoutçœ‹åšè´å¶æ–¯è¿‘ä¼¼çš„ç»å…¸è®ºæ–‡ï¼‰
- **Kendall, A., & Gal, Y. (2017). What uncertainties do we need in bayesian deep learning for computer vision?.Â _Advances in neural information processing systems_,Â _30_.ï¼ˆä¸ç¡®å®šæ€§ä¼°è®¡å¿…è¯»è®ºæ–‡ï¼Œå°†ä¸ç¡®å®šæ€§åˆ†ä¸ºæ•°æ®ä¸ç¡®å®šæ€§ä»¥åŠæ¨¡å‹ä¸ç¡®å®šæ€§ï¼Œå¹¶ä»‹ç»äº†åœ¨åˆ†ç±»å’Œå›å½’ä¸­ä¸ç¡®å®šæ€§ä¼°è®¡çš„å»ºæ¨¡æ–¹æ³•ï¼‰**
- Louizos, C., & Welling, M. (2017, July). Multiplicative normalizing flows for variational bayesian neural networks. InÂ _International Conference on Machine Learning_Â (pp. 2218-2227). PMLR.ï¼ˆå˜åˆ†è´å¶æ–¯ç¥ç»ç½‘ç»œï¼ŒEDLè®ºæ–‡ä¸­çš„å¯¹æ¯”æ–¹æ³•ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ3ï¼‰é›†æˆæ–¹æ³•
- Lakshminarayanan, B., Pritzel, A., & Blundell, C. (2017). Simple and scalable predictive uncertainty estimation using deep ensembles.Â _Advances in neural information processing systems_,Â _30_.ï¼ˆé›†æˆæ–¹æ³•çš„å¼€å±±ä¹‹ä½œï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ4ï¼‰è¯æ®æ·±åº¦å­¦ä¹ 
- **Sensoy, M., Kaplan, L., & Kandemir, M. (2018). Evidential deep learning to quantify classification uncertainty.Â _Advances in neural information processing systems_,Â _31_.ï¼ˆè¯æ®åˆ†ç±»ï¼‰**
- **Amini, A., Schwarting, W., Soleimany, A., & Rus, D. (2020). Deep evidential regression.Â _Advances in Neural Information Processing Systems_,Â _33_, 14927-14937.ï¼ˆè¯æ®å›å½’ï¼‰**
- Ulmer, D. (2021). A survey on evidential deep learning for single-pass uncertainty estimation.Â _arXiv preprint arXiv:2110.03051_.ï¼ˆè¯æ®ä¸ç¡®å®šæ€§ç»¼è¿°ï¼‰
- Zhao, X., Ou, Y., Kaplan, L., Chen, F., & Cho, J. H. (2019). Quantifying classification uncertainty using regularized evidential neural networks.Â _arXiv preprint arXiv:1910.06864_.ï¼ˆè¯æ®åŸºç¡€ä¸Šæ·»åŠ æ­£åˆ™åŒ–é¡¹ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
### 4ã€ä¸ç¡®å®šæ€§ä¼°è®¡åœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨
#### ï¼ˆ1ï¼‰åˆ†å‰²
- Kwon, Y., Won, J. H., Kim, B. J., & Paik, M. C. (2020). Uncertainty quantification using Bayesian neural networks in classification: Application to biomedical image segmentation.Â _Computational Statistics & Data Analysis_,Â _142_, 106816.ï¼ˆè´å¶æ–¯ä¸ç¡®å®šæ€§ï¼‰
- Li, H., Nan, Y., Del Ser, J., & Yang, G. (2022). Region-based evidential deep learning to quantify uncertainty and improve robustness of brain tumor segmentation.Â _Neural Computing and Applications_, 1-15.ï¼ˆè¯æ®ä¸ç¡®å®šæ€§ï¼‰
- Zou, K., Yuan, X., Shen, X., Chen, Y., Wang, M., Goh, R. S. M., ... & Fu, H. (2023). EvidenceCap: Towards trustworthy medical image segmentation via evidential identity cap.Â _arXiv preprint arXiv:2301.00349_.ï¼ˆè¯æ®ä¸ç¡®å®šæ€§ï¼‰
- Zhou, X., Yue, X., Xu, Z., Denoeux, T., & Chen, Y. (2021, December). Deep neural networks with prior evidence for bladder cancer staging. InÂ _2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)_Â (pp. 1221-1226). IEEE.ï¼ˆè¯æ®åŒ»å­¦å½±åƒåˆ†å‰²ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ2ï¼‰ç›®æ ‡æ£€æµ‹
- Harakeh, A., Smart, M., & Waslander, S. L. (2020, May). Bayesod: A bayesian approach for uncertainty estimation in deep object detectors. InÂ _2020 IEEE International Conference on Robotics and Automation (ICRA)_Â (pp. 87-93). IEEE.ï¼ˆç›®æ ‡æ£€æµ‹ä¸­çš„è´å¶æ–¯ä¸ç¡®å®šæ€§ä¼°è®¡ï¼‰
- Feng, D., Harakeh, A., Waslander, S. L., & Dietmayer, K. (2021). A review and comparative study on probabilistic object detection in autonomous driving.Â _IEEE Transactions on Intelligent Transportation Systems_,Â _23_(8), 9961-9980.ï¼ˆè‡ªåŠ¨é©¾é©¶ä¸­çš„æ¦‚ç‡ç›®æ ‡æ£€æµ‹ï¼‰
- Hang, Q., Li, Z., Dong, Y., & Yue, X. (2022, November). Uncertainty-Aware Deep Open-Set Object Detection. InÂ _Rough Sets: International Joint Conference, IJCRS 2022, Suzhou, China, November 11â€“14, 2022, Proceedings_Â (pp. 161-175). Cham: Springer Nature Switzerland.ï¼ˆè¯æ®ç›®æ ‡æ£€æµ‹ï¼‰
- - Miller, D. (2021).Â _Epistemic uncertainty estimation for object detection in open-set conditions_Â (Doctoral dissertation, Queensland University of Technology).ï¼ˆå¼€é›†ç›®æ ‡æ£€æµ‹ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ3ï¼‰å¼€é›†è¯†åˆ«
- Bao, W., Yu, Q., & Kong, Y. (2021). Evidential deep learning for open set action recognition. InÂ _Proceedings of the IEEE/CVF International Conference on Computer Vision_Â (pp. 13349-13358).ï¼ˆå¼€é›†è¯†åˆ«ï¼‰
- CorbiÃ¨re, C., Lafon, M., Thome, N., Cord, M., & PÃ©rez, P. (2021, September). Beyond First-Order Uncertainty Estimation with Evidential Models for Open-World Recognition. InÂ _ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning_.ï¼ˆæ­£åˆ™åŒ–é¡¹ï¼‰
- CorbiÃ¨re, C., Lafon, M., Thome, N., Cord, M., & PÃ©rez, P. (2021, September). Beyond First-Order Uncertainty Estimation with Evidential Models for Open-World Recognition. InÂ _ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning_.ï¼ˆè¯æ®ç”¨äºå¼€æ”¾ä¸–ç•Œè¯†åˆ«ï¼‰
- Mundt, M., Pliushch, I., Majumder, S., & Ramesh, V. (2019). Open set recognition through deep neural network uncertainty: Does out-of-distribution detection require generative classifiers?. InÂ _Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops_.ï¼ˆOODæ£€æµ‹ï¼‰
- - Zhou, T., Han, T., & Droguett, E. L. (2022). Towards trustworthy machine fault diagnosis: A probabilistic Bayesian deep learning framework.Â _Reliability Engineering & System Safety_,Â _224_, 108525.ï¼ˆè´å¶æ–¯æ•…éšœè¯Šæ–­ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ4ï¼‰åˆ†å¸ƒå¤–æ³›åŒ–
- Chen, L., Lou, Y., He, J., Bai, T., & Deng, M. (2022, June). Evidential neighborhood contrastive learning for universal domain adaptation. InÂ _Proceedings of the AAAI Conference on Artificial Intelligence_Â (Vol. 36, No. 6, pp. 6258-6267).ï¼ˆè¯æ®é¢†åŸŸå¯¹æ¯”å­¦ä¹ ï¼‰
- Qiao, F., & Peng, X. (2021). Uncertainty-guided model generalization to unseen domains. InÂ _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_Â (pp. 6790-6800).ï¼ˆä¸ç¡®å®šæ€§æŒ‡å¯¼çš„æ•°æ®å¢å¹¿ï¼‰
- Zhao, L., Liu, T., Peng, X., & Metaxas, D. (2020). Maximum-entropy adversarial data augmentation for improved generalization and robustness.Â _Advances in Neural Information Processing Systems_,Â _33_, 14435-14447.ï¼ˆå¯¹æŠ—æ•°æ®å¢å¹¿-æœ€å¤§ç†µï¼‰
- Li, X., Dai, Y., Ge, Y., Liu, J., Shan, Y., & Duan, L. Y. (2022). Uncertainty modeling for out-of-distribution generalization.Â _arXiv preprint arXiv:2202.03958_.ï¼ˆOODGçš„ä¸ç¡®å®šæ€§å»ºæ¨¡ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ5ï¼‰å¤šè§†å›¾å­¦ä¹ 
- Han, Z., Zhang, C., Fu, H., & Zhou, J. T. (2022). Trusted multi-view classification with dynamic evidential fusion.Â _IEEE transactions on pattern analysis and machine intelligence_.ï¼ˆè¯æ®å¤šè§†å›¾åˆ†ç±»ï¼‰
- Ma, H., Han, Z., Zhang, C., Fu, H., Zhou, J. T., & Hu, Q. (2021). Trustworthy multimodal regression with mixture of normal-inverse gamma distributions.Â _Advances in Neural Information Processing Systems_,Â _34_, 6881-6893.ï¼ˆè¯æ®å¤šæ¨¡æ€å›å½’ï¼‰
- Geng, Y., Han, Z., Zhang, C., & Hu, Q. (2021, May). Uncertainty-aware multi-view representation learning. InÂ _Proceedings of the AAAI Conference on Artificial Intelligence_Â (Vol. 35, No. 9, pp. 7545-7553).ï¼ˆå¤šè§†å›¾å›å½’-æ•°æ®ä¸ç¡®å®šæ€§å»ºæ¨¡ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)

## äºŒã€ä»£ç å’Œæ•°æ®é›†
ç›¸å…³è®ºæ–‡çš„ä»£ç ä»¥åŠæ•°æ®é›†å¯ä»¥åœ¨[Paper With Code ](https://paperswithcode.com/)æœç´¢è·å–ï¼Œå¦‚æœPaper With Code ä¸­æ²¡æœ‰æ”¶å½•ï¼Œå¯ç›´æ¥åœ¨GitHubè¾“å…¥è®ºæ–‡å…³é”®å­—æœç´¢ç›¸å…³ä»£ç 
## ä¸‰ã€åšå®¢
##### 1ã€å› æœæ¨ç†

##### 2ã€å› æœè¡¨å¾å­¦ä¹ 

##### 3ã€ä¸ç¡®å®šæ€§ä¼°è®¡





<br>



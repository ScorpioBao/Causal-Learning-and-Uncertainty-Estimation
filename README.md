# Cusal-Learning-and-uncertainty-estimation
è¯¥ç«™ç‚¹æ•´ç†äº†â€å› æœæ¨ç†ä¸ä¸ç¡®å®šæ€§ä¼°è®¡â€œç›¸å…³ç ”ç©¶æ–¹å‘çš„è®ºæ–‡ã€ä»£ç ã€åšå®¢ç­‰å­¦ä¹ èµ„æºã€‚
# ç›®å½•
#### ä¸€ã€è®ºæ–‡
- [å› æœæ¨ç†](https://github.com/ScorpioBao/Causal-Learning-and-Uncertainty-Estimation/tree/master/Causal%20Learning)
	- [å› æœæ•ˆåº”è¯„ä¼°ï¼ˆCausal Effect Estimationï¼‰](https://github.com/ScorpioBao/Causal-Learning-and-Uncertainty-Estimation/tree/master/Causal%20Learning/Causal%20Effect%20Estmation))
	- [å› æœå‘ç°ï¼ˆCausal Discoveryï¼‰](https://github.com/ScorpioBao/Causal-Learning-and-Uncertainty-Estimation/tree/master/Causal%20Learning/Causal%20Discovery)
- [å› æœè¡¨å¾å­¦ä¹ ](#2å› æœè¡¨å¾å­¦ä¹ )
	- [ç»¼è¿°](#1ç»¼è¿°)
	- [åˆ†å¸ƒå¤–æ³›åŒ–ï¼ˆOut-of-Distribution Generalizationï¼‰](#2åˆ†å¸ƒå¤–æ³›åŒ–)
	- [ç¨³å®šå­¦ä¹ ï¼ˆStable Learningï¼‰](#3ç¨³å®šå­¦ä¹ )
	- [æ¶ˆé™¤åå·®ï¼ˆDebiasï¼‰](#4æ¶ˆé™¤åå·®)
-  [ä¸ç¡®å®šæ€§ä¼°è®¡](#3ä¸ç¡®å®šæ€§ä¼°è®¡)
	- [ç»¼è¿°](#1ç»¼è¿°)
	- [è´å¶æ–¯æ–¹æ³•ï¼ˆBayesianï¼‰](#2è´å¶æ–¯æ–¹æ³•)
	- [é›†æˆæ–¹æ³•ï¼ˆEnsembleï¼‰](#3é›†æˆæ–¹æ³•)
	- [è¯æ®æ·±åº¦å­¦ä¹ ï¼ˆEvidential Deep Learning)](#4è¯æ®æ·±åº¦å­¦ä¹ )
- [ ä¸ç¡®å®šæ€§ä¼°è®¡åœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨](#4ä¸ç¡®å®šæ€§ä¼°è®¡åœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨)
	- [åˆ†å‰²](#1åˆ†å‰²)
	- [ç›®æ ‡æ£€æµ‹](#2ç›®æ ‡æ£€æµ‹)
	- [å¼€é›†è¯†åˆ«](#3å¼€é›†è¯†åˆ«)
	- [åˆ†å¸ƒå¤–æ³›åŒ–](#4åˆ†å¸ƒå¤–æ³›åŒ–)
	- [å¤šè§†å›¾å­¦ä¹ ](#5å¤šè§†å›¾å­¦ä¹ )
- [æ·±åº¦å­¦ä¹ æ¨¡å‹æ ¡å‡†çš„ç›¸å…³å·¥ä½œ](#5æ·±åº¦å­¦ä¹ æ¨¡å‹æ ¡å‡†çš„ç›¸å…³å·¥ä½œ)
- [ä»£ç å’Œæ•°æ®é›†](#äºŒä»£ç å’Œæ•°æ®é›†)
- [åšå®¢](#ä¸‰åšå®¢)
	- [å› æœæ¨ç†](#1å› æœæ¨ç†)
	- [ä¸ç¡®å®šæ€§ä¼°è®¡](#2ä¸ç¡®å®šæ€§ä¼°è®¡)
- [äº¤æµ](#å››äº¤æµ)
# ä¸€ã€è®ºæ–‡
### 1ã€ å› æœæ¨ç†(ç›¸å…³è®ºæ–‡å¯ä»¥é€šè¿‡ç›®å½•ä¸­çš„é“¾æ¥è®¿é—®)
### 2ã€ å› æœè¡¨å¾å­¦ä¹ 
#### ï¼ˆ1ï¼‰ç»¼è¿°
- SchÃ¶lkopf, B., Locatello, F., Bauer, S., Ke, N. R., Kalchbrenner, N., Goyal, A., & Bengio, Y. (2021). Toward causal representation learning.Â _Proceedings of the IEEE_,Â _109_(5), 612-634.ï¼ˆå› æœè¡¨å¾å­¦ä¹ ç»¼è¿°ï¼‰
- Lu, C., Wu, Y., HernÃ¡ndez-Lobato, J. M., & SchÃ¶lkopf, B. (2021). Invariant causal representation learning for out-of-distribution generalization. InÂ _International Conference on Learning Representations_.ï¼ˆä¸å˜å› æœè¡¨å¾å­¦ä¹ ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ2ï¼‰åˆ†å¸ƒå¤–æ³›åŒ–
*ç›¸å…³è®ºæ–‡å¯ä»¥åœ¨[åˆ†å¸ƒå¤–æ³›åŒ–](https://github.com/ScorpioBao/Causal-Learning-and-Uncertainty-Estimation/tree/master/Causal%20Representation%20Learning/Out-of-Distribution%20Generalization)æ–‡ä»¶å¤¹ä¸‹æŸ¥çœ‹*
- Xu, R., Zhang, X., Shen, Z., Zhang, T., & Cui, P. (2022, June). A Theoretical Analysis on Independence-driven Importance Weighting for Covariate-shift Generalization. InÂ _International Conference on Machine Learning_Â (pp. 24803-24829). PMLR.ï¼ˆåå˜é‡åç§»ï¼‰
- Liu, C., Sun, X., Wang, J., Tang, H., Li, T., Qin, T., ... & Liu, T. Y. (2021). Learning causal semantic representation for out-of-distribution prediction.Â _Advances in Neural Information Processing Systems_,Â _34_, 6155-6170.ï¼ˆå› æœè¯­ä¹‰è¡¨ç¤ºå­¦ä¹ ï¼‰
- Zhang, X., Xu, Z., Xu, R., Liu, J., Cui, P., Wan, W., ... & Li, C. (2022). Towards domain generalization in object detection.Â _arXiv preprint arXiv:2203.14387_.ï¼ˆç›®æ ‡æ£€æµ‹ä¸­çš„åŸŸæ³›åŒ–ï¼‰
- Shen, Z., Liu, J., He, Y., Zhang, X., Xu, R., Yu, H., & Cui, P. (2021). Towards out-of-distribution generalization: A survey.Â _arXiv preprint arXiv:2108.13624_.ï¼ˆç»¼è¿°ï¼‰
- Li, X., Dai, Y., Ge, Y., Liu, J., Shan, Y., & Duan, L. Y. (2022). Uncertainty modeling for out-of-distribution generalization.Â _arXiv preprint arXiv:2202.03958_.ï¼ˆOODGä¸ç¡®å®šæ€§å»ºæ¨¡ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ3ï¼‰ç¨³å®šå­¦ä¹ 
*ç›¸å…³è®ºæ–‡å¯ä»¥åœ¨[ç¨³å®šå­¦ä¹ ](https://github.com/ScorpioBao/Causal-Learning-and-Uncertainty-Estimation/tree/master/Causal%20Representation%20Learning/Stable%20Learning)æ–‡ä»¶å¤¹ä¸‹æŸ¥çœ‹*
- Zhang, X., Cui, P., Xu, R., Zhou, L., He, Y., & Shen, Z. (2021). Deep stable learning for out-of-distribution generalization. InÂ _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_Â (pp. 5372-5382).ï¼ˆStableNetï¼‰
- Liu, J., Hu, Z., Cui, P., Li, B., & Shen, Z. (2021, July). Heterogeneous risk minimization. InÂ _International Conference on Machine Learning_Â (pp. 6804-6814). PMLR.ï¼ˆå¼‚è´¨é£é™©æœ€å°åŒ–ï¼‰
- Cui, P., & Athey, S. (2022). Stable learning establishes some common ground between causal inference and machine learning.Â _Nature Machine Intelligence_,Â _4_(2), 110-115.ï¼ˆç¨³å®šå­¦ä¹ ä¸å› æœæ¨æ–­å’Œæœºå™¨å­¦ä¹ ä¹‹é—´çš„å…±åŒç‚¹ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ4ï¼‰æ¶ˆé™¤åå·®
- Wang, T., Zhou, C., Sun, Q., & Zhang, H. (2021). Causal attention for unbiased visual recognition. InÂ _Proceedings of the IEEE/CVF International Conference on Computer Vision_Â (pp. 3091-3100).ï¼ˆå› æœæ³¨æ„åŠ›ï¼‰
- Niu, Y., Tang, K., Zhang, H., Lu, Z., Hua, X. S., & Wen, J. R. (2021). Counterfactual vqa: A cause-effect look at language bias. InÂ _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_Â (pp. 12700-12710).ï¼ˆåäº‹å®VQAï¼‰
- Yang, X., Zhang, H., & Cai, J. (2021). Deconfounded image captioning: A causal retrospect.Â _IEEE Transactions on Pattern Analysis and Machine Intelligence_.ï¼ˆå»é™¤æ··æ·†åå·®ï¼‰
- Nam, J., Cha, H., Ahn, S., Lee, J., & Shin, J. (2020). Learning from failure: De-biasing classifier from biased classifier.Â _Advances in Neural Information Processing Systems_,Â _33_, 20673-20684.ï¼ˆä»æœ‰ååˆ†ç±»å™¨å­¦ä¹ å»ååˆ†ç±»å™¨ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
### 3ã€ä¸ç¡®å®šæ€§ä¼°è®¡
#### ï¼ˆ1ï¼‰ç»¼è¿°
- Gawlikowski, J., Tassi, C. R. N., Ali, M., Lee, J., Humt, M., Feng, J., ... & Zhu, X. X. (2021). A survey of uncertainty in deep neural networks.Â _arXiv preprint arXiv:2107.03342_.
- Abdar, M., Pourpanah, F., Hussain, S., Rezazadegan, D., Liu, L., Ghavamzadeh, M., ... & Nahavandi, S. (2021). A review of uncertainty quantification in deep learning: Techniques, applications and challenges.Â _Information Fusion_,Â _76_, 243-297.
- Uncertainty in Deep Learningï¼ˆGalåšå£«è®ºæ–‡ï¼‰
- He, W., & Jiang, Z. (2023). A Survey on Uncertainty Quantification Methods for Deep Neural Networks: An Uncertainty Source Perspective.Â _arXiv preprint arXiv:2302.13425_.
- HÃ¼llermeier, E., & Waegeman, W. (2021). Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods.Â _Machine Learning_,Â _110_, 457-506.ï¼ˆæ•°æ®å’Œæ¨¡å‹ä¸ç¡®å®šæ€§ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ2ï¼‰è´å¶æ–¯æ–¹æ³•ï¼š
- Gal, Y., & Ghahramani, Z. (2016, June). Dropout as a bayesian approximation: Representing model uncertainty in deep learning. InÂ _international conference on machine learning_Â (pp. 1050-1059). PMLR.ï¼ˆå°†Dropoutçœ‹åšè´å¶æ–¯è¿‘ä¼¼çš„ç»å…¸è®ºæ–‡ï¼‰
- **Kendall, A., & Gal, Y. (2017). What uncertainties do we need in bayesian deep learning for computer vision?.Â _Advances in neural information processing systems_,Â _30_.ï¼ˆä¸ç¡®å®šæ€§ä¼°è®¡å¿…è¯»è®ºæ–‡ï¼Œå°†ä¸ç¡®å®šæ€§åˆ†ä¸ºæ•°æ®ä¸ç¡®å®šæ€§ä»¥åŠæ¨¡å‹ä¸ç¡®å®šæ€§ï¼Œå¹¶ä»‹ç»äº†åœ¨åˆ†ç±»å’Œå›å½’ä¸­ä¸ç¡®å®šæ€§ä¼°è®¡çš„å»ºæ¨¡æ–¹æ³•ï¼‰**
- Louizos, C., & Welling, M. (2017, July). Multiplicative normalizing flows for variational bayesian neural networks. InÂ _International Conference on Machine Learning_Â (pp. 2218-2227). PMLR.ï¼ˆå˜åˆ†è´å¶æ–¯ç¥ç»ç½‘ç»œï¼ŒEDLè®ºæ–‡ä¸­çš„å¯¹æ¯”æ–¹æ³•ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ3ï¼‰é›†æˆæ–¹æ³•
- Lakshminarayanan, B., Pritzel, A., & Blundell, C. (2017). Simple and scalable predictive uncertainty estimation using deep ensembles.Â _Advances in neural information processing systems_,Â _30_.ï¼ˆé›†æˆæ–¹æ³•çš„å¼€å±±ä¹‹ä½œï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ4ï¼‰è¯æ®æ·±åº¦å­¦ä¹ 
- **Sensoy, M., Kaplan, L., & Kandemir, M. (2018). Evidential deep learning to quantify classification uncertainty.Â _Advances in neural information processing systems_,Â _31_.ï¼ˆè¯æ®åˆ†ç±»ï¼‰**
- **Amini, A., Schwarting, W., Soleimany, A., & Rus, D. (2020). Deep evidential regression.Â _Advances in Neural Information Processing Systems_,Â _33_, 14927-14937.ï¼ˆè¯æ®å›å½’ï¼‰**
- Sensoy, M., Kaplan, L., Cerutti, F., & Saleki, M. (2020, April). Uncertainty-aware deep classifiers using generative models. InÂ _Proceedings of the AAAI Conference on Artificial Intelligence_Â (Vol. 34, No. 04, pp. 5620-5627).ï¼ˆEDLä½œè€…çš„å¦ä¸€ç¯‡è®ºæ–‡ï¼‰
- Malinin, A., & Gales, M. (2018). Predictive uncertainty estimation via prior networks.Â _Advances in neural information processing systems_,Â _31_.ï¼ˆåŒæ ·ä½¿ç”¨ç‹„åˆ©å…‹é›·åˆ†å¸ƒå»ºæ¨¡ä¸ç¡®å®šæ€§çš„å¦ä¸€ç§æ–¹æ³•ï¼‰
- Ulmer, D. (2021). A survey on evidential deep learning for single-pass uncertainty estimation.Â _arXiv preprint arXiv:2110.03051_.ï¼ˆè¯æ®ä¸ç¡®å®šæ€§ç»¼è¿°ï¼‰
- Zhao, X., Ou, Y., Kaplan, L., Chen, F., & Cho, J. H. (2019). Quantifying classification uncertainty using regularized evidential neural networks.Â _arXiv preprint arXiv:1910.06864_.ï¼ˆè¯æ®åŸºç¡€ä¸Šæ·»åŠ æ­£åˆ™åŒ–é¡¹ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
### 4ã€ä¸ç¡®å®šæ€§ä¼°è®¡åœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨
#### ï¼ˆ1ï¼‰åˆ†å‰²
- Kwon, Y., Won, J. H., Kim, B. J., & Paik, M. C. (2020). Uncertainty quantification using Bayesian neural networks in classification: Application to biomedical image segmentation.Â _Computational Statistics & Data Analysis_,Â _142_, 106816.ï¼ˆè´å¶æ–¯ä¸ç¡®å®šæ€§ï¼‰
- Li, H., Nan, Y., Del Ser, J., & Yang, G. (2022). Region-based evidential deep learning to quantify uncertainty and improve robustness of brain tumor segmentation.Â _Neural Computing and Applications_, 1-15.ï¼ˆè¯æ®ä¸ç¡®å®šæ€§ï¼‰
- Zou, K., Yuan, X., Shen, X., Chen, Y., Wang, M., Goh, R. S. M., ... & Fu, H. (2023). EvidenceCap: Towards trustworthy medical image segmentation via evidential identity cap.Â _arXiv preprint arXiv:2301.00349_.ï¼ˆè¯æ®ä¸ç¡®å®šæ€§ï¼‰
- Zhou, X., Yue, X., Xu, Z., Denoeux, T., & Chen, Y. (2021, December). Deep neural networks with prior evidence for bladder cancer staging. InÂ _2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)_Â (pp. 1221-1226). IEEE.ï¼ˆè¯æ®åŒ»å­¦å½±åƒåˆ†å‰²ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ2ï¼‰ç›®æ ‡æ£€æµ‹
- Harakeh, A., Smart, M., & Waslander, S. L. (2020, May). Bayesod: A bayesian approach for uncertainty estimation in deep object detectors. InÂ _2020 IEEE International Conference on Robotics and Automation (ICRA)_Â (pp. 87-93). IEEE.ï¼ˆç›®æ ‡æ£€æµ‹ä¸­çš„è´å¶æ–¯ä¸ç¡®å®šæ€§ä¼°è®¡ï¼‰
- Feng, D., Harakeh, A., Waslander, S. L., & Dietmayer, K. (2021). A review and comparative study on probabilistic object detection in autonomous driving.Â _IEEE Transactions on Intelligent Transportation Systems_,Â _23_(8), 9961-9980.ï¼ˆè‡ªåŠ¨é©¾é©¶ä¸­çš„æ¦‚ç‡ç›®æ ‡æ£€æµ‹ï¼‰
- Hang, Q., Li, Z., Dong, Y., & Yue, X. (2022, November). Uncertainty-Aware Deep Open-Set Object Detection. InÂ _Rough Sets: International Joint Conference, IJCRS 2022, Suzhou, China, November 11â€“14, 2022, Proceedings_Â (pp. 161-175). Cham: Springer Nature Switzerland.ï¼ˆè¯æ®ç›®æ ‡æ£€æµ‹ï¼‰
- Miller, D. (2021).Â _Epistemic uncertainty estimation for object detection in open-set conditions_Â (Doctoral dissertation, Queensland University of Technology).ï¼ˆå¼€é›†ç›®æ ‡æ£€æµ‹ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ3ï¼‰å¼€é›†è¯†åˆ«
- Bao, W., Yu, Q., & Kong, Y. (2021). Evidential deep learning for open set action recognition. InÂ _Proceedings of the IEEE/CVF International Conference on Computer Vision_Â (pp. 13349-13358).ï¼ˆå¼€é›†è¯†åˆ«ï¼‰
- CorbiÃ¨re, C., Lafon, M., Thome, N., Cord, M., & PÃ©rez, P. (2021, September). Beyond First-Order Uncertainty Estimation with Evidential Models for Open-World Recognition. InÂ _ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning_.ï¼ˆæ­£åˆ™åŒ–é¡¹ï¼‰
- CorbiÃ¨re, C., Lafon, M., Thome, N., Cord, M., & PÃ©rez, P. (2021, September). Beyond First-Order Uncertainty Estimation with Evidential Models for Open-World Recognition. InÂ _ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning_.ï¼ˆè¯æ®ç”¨äºå¼€æ”¾ä¸–ç•Œè¯†åˆ«ï¼‰
- Mundt, M., Pliushch, I., Majumder, S., & Ramesh, V. (2019). Open set recognition through deep neural network uncertainty: Does out-of-distribution detection require generative classifiers?. InÂ _Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops_.ï¼ˆOODæ£€æµ‹ï¼‰
- Zhou, T., Han, T., & Droguett, E. L. (2022). Towards trustworthy machine fault diagnosis: A probabilistic Bayesian deep learning framework.Â _Reliability Engineering & System Safety_,Â _224_, 108525.ï¼ˆè´å¶æ–¯æ•…éšœè¯Šæ–­ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ4ï¼‰åˆ†å¸ƒå¤–æ³›åŒ–
- Chen, L., Lou, Y., He, J., Bai, T., & Deng, M. (2022, June). Evidential neighborhood contrastive learning for universal domain adaptation. InÂ _Proceedings of the AAAI Conference on Artificial Intelligence_Â (Vol. 36, No. 6, pp. 6258-6267).ï¼ˆè¯æ®é¢†åŸŸå¯¹æ¯”å­¦ä¹ ï¼‰
- Qiao, F., & Peng, X. (2021). Uncertainty-guided model generalization to unseen domains. InÂ _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_Â (pp. 6790-6800).ï¼ˆä¸ç¡®å®šæ€§æŒ‡å¯¼çš„æ•°æ®å¢å¹¿ï¼‰
- Zhao, L., Liu, T., Peng, X., & Metaxas, D. (2020). Maximum-entropy adversarial data augmentation for improved generalization and robustness.Â _Advances in Neural Information Processing Systems_,Â _33_, 14435-14447.ï¼ˆå¯¹æŠ—æ•°æ®å¢å¹¿-æœ€å¤§ç†µï¼‰
- Li, X., Dai, Y., Ge, Y., Liu, J., Shan, Y., & Duan, L. Y. (2022). Uncertainty modeling for out-of-distribution generalization.Â _arXiv preprint arXiv:2202.03958_.ï¼ˆOODGçš„ä¸ç¡®å®šæ€§å»ºæ¨¡ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
#### ï¼ˆ5ï¼‰å¤šè§†å›¾å­¦ä¹ 
- Han, Z., Zhang, C., Fu, H., & Zhou, J. T. (2022). Trusted multi-view classification with dynamic evidential fusion.Â _IEEE transactions on pattern analysis and machine intelligence_.ï¼ˆè¯æ®å¤šè§†å›¾åˆ†ç±»ï¼‰
- Ma, H., Han, Z., Zhang, C., Fu, H., Zhou, J. T., & Hu, Q. (2021). Trustworthy multimodal regression with mixture of normal-inverse gamma distributions.Â _Advances in Neural Information Processing Systems_,Â _34_, 6881-6893.ï¼ˆè¯æ®å¤šæ¨¡æ€å›å½’ï¼‰
- Geng, Y., Han, Z., Zhang, C., & Hu, Q. (2021, May). Uncertainty-aware multi-view representation learning. InÂ _Proceedings of the AAAI Conference on Artificial Intelligence_Â (Vol. 35, No. 9, pp. 7545-7553).ï¼ˆå¤šè§†å›¾å›å½’-æ•°æ®ä¸ç¡®å®šæ€§å»ºæ¨¡ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
### 5ã€æ·±åº¦å­¦ä¹ æ¨¡å‹æ ¡å‡†çš„ç›¸å…³å·¥ä½œ
- **Guo, C., Pleiss, G., Sun, Y., & Weinberger, K. Q. (2017, July). On calibration of modern neural networks. InÂ _International conference on machine learning_Â (pp. 1321-1330). PMLR.ï¼ˆåˆ†ç±»æ ¡å‡†ï¼‰**
- **Kuleshov, V., Fenner, N., & Ermon, S. (2018, July). Accurate uncertainties for deep learning using calibrated regression. InÂ _International conference on machine learning_Â (pp. 2796-2804). PMLR.ï¼ˆå›å½’æ ¡å‡†ï¼‰**
- Mukhoti, J., Kulharia, V., Sanyal, A., Golodetz, S., Torr, P., & Dokania, P. (2020). Calibrating deep neural networks using focal loss.Â _Advances in Neural Information Processing Systems_,Â _33_, 15288-15299.ï¼ˆFocal Loss æ ¡å‡†åˆ†ç±»ï¼‰
- Krishnan, R., & Tickoo, O. (2020). Improving model calibration with accuracy versus uncertainty optimization.Â _Advances in Neural Information Processing Systems_,Â _33_, 18237-18248.ï¼ˆè€ƒè™‘ä¸ç¡®å®šæ€§æ ¡å‡†æ¨¡å‹ï¼‰
- Thulasidasan, S., Chennupati, G., Bilmes, J. A., Bhattacharya, T., & Michalak, S. (2019). On mixup training: Improved calibration and predictive uncertainty for deep neural networks.Â _Advances in Neural Information Processing Systems_,Â _32_.ï¼ˆmixupæé«˜æ¨¡å‹æ ¡å‡†æ€§èƒ½ï¼‰

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)

## äºŒã€ä»£ç å’Œæ•°æ®é›†
ç›¸å…³è®ºæ–‡çš„ä»£ç ä»¥åŠæ•°æ®é›†å¯ä»¥åœ¨[Paper With Code ](https://paperswithcode.com/)æœç´¢è·å–ï¼Œå¦‚æœPaper With Code ä¸­æ²¡æœ‰æ”¶å½•ï¼Œå¯ç›´æ¥åœ¨GitHubè¾“å…¥è®ºæ–‡å…³é”®å­—æœç´¢ç›¸å…³ä»£ç 

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
## ä¸‰ã€åšå®¢
### 1ã€å› æœæ¨ç†
- [e-CARE: å¯è§£é‡Šçš„å› æœæ¨ç†è¯„æµ‹ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzIxMjAzNDY5Mg==&mid=2650805534&idx=1&sn=ecf1c78e642f46daa10c1217c3bd320d&chksm=8cb880f5bbcf09e3d060f3b96fb24c42ee60c52a1b10914e3af637e8f07c9c88c5ca6f02d17a#rd)
- [ã€Valse - å´”é¹ã€‘Out-of-Distribution åˆ†å¸ƒå¤–æ³›åŒ– - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/419346109)
- [å´”é¹å›¢é˜Ÿï¼šä¸‡å­—é•¿æ–‡æ¢³ç†ã€Œç¨³å®šå­¦ä¹ ã€å…¨æ™¯å›¾ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/535602186)
- [ã€ç»¼è¿°ã€‘ç¦»ç¾¤/å¼‚å¸¸/æ–°ç±»æ£€æµ‹ï¼Ÿå¼€é›†è¯†åˆ«ï¼Ÿåˆ†å¸ƒå¤–æ£€æµ‹ï¼Ÿä¸€æ–‡ææ‡‚å…¶é—´å¼‚åŒï¼ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/426521773)
-  [å› æœè¡¨å¾å­¦ä¹ æœ€æ–°ç»¼è¿°ï¼šè¿æ¥å› æœç§‘å­¦å’Œæœºå™¨å­¦ä¹ çš„æ¡¥æ¢ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/355009051)
- [å› æœæ¨æ–­ï¼šå› æœè¡¨å¾å­¦ä¹ çš„CVè½åœ° - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/400043237)

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
### 2ã€ä¸ç¡®å®šæ€§ä¼°è®¡
- [(184æ¡æ¶ˆæ¯) What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? è®¡ç®—æœºè§†è§‰ç”¨äºè´å¶æ–¯æ·±åº¦å­¦ä¹ çš„ä¸ç¡®å®šæ€§_Xieyuanli_Chençš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/weixin_39779106/article/details/78968982#1%E5%B0%86%E5%BC%82%E6%96%B9%E5%B7%AE%E5%81%B6%E7%84%B6%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E5%92%8C%E8%AE%A4%E7%9F%A5%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9B%B8%E7%BB%93%E5%90%88%5D(https://blog.csdn.net/weixin_39779106/article/details/78968982#1%E5%B0%86%E5%BC%82%E6%96%B9%E5%B7%AE%E5%81%B6%E7%84%B6%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E5%92%8C%E8%AE%A4%E7%9F%A5%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9B%B8%E7%BB%93%E5%90%88))
- [Bayesian inference problem, MCMC and variational inference | by Joseph Rocca | Towards Data Science](https://towardsdatascience.com/bayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29)
- [Uncertainty Estimation in CV - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/166617220)
- [What my deep model doesn't know... | Yarin Gal - Blog | Oxford Machine Learning](http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html)
- [Uncertainty in Deep Learning. How ToÂ Measure? | Towards Data Science](https://towardsdatascience.com/my-deep-learning-model-says-sorry-i-dont-know-the-answer-that-s-absolutely-ok-50ffa562cb0b)
- https://www.bilibili.com/video/BV1RJ411D7QA/
- [å¦‚ä½•åˆ›é€ å¯ä¿¡ä»»çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Ÿå…ˆè¦ç†è§£ä¸ç¡®å®šæ€§ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650755237&idx=3&sn=55beb3edcef0bb4ded4b56e1379efbda&chksm=871a94dbb06d1dcddc49272f77899561c0da5760f2dc6cfebd3877272a959e01c69105a8bac2#rd)
- [ä»æœ€å¤§ä¼¼ç„¶åˆ°EMç®—æ³•ï¼šä¸€è‡´çš„ç†è§£æ–¹å¼ - ç§‘å­¦ç©ºé—´|Scientific Spaces (kexue.fm)](https://kexue.fm/archives/5239)
- [ICMLé«˜å¼•æ¨¡å‹æ ¡å‡†è®ºæ–‡ï¼Œä¸€ä¸ªå¥½çš„å·¥ä½œæ˜¯æ€æ ·çš„ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/323959089)

ğŸ‘† [<b>BACK to Table of Contents</b> -->](#ç›®å½•)
## å››ã€äº¤æµ
- Email: senlinbao@gmail.com





<br>


